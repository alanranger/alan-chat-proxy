// /api/chat.js
export const config = { runtime: 'nodejs' };

/**
 * Chat endpoint that:
 * 1) Calls your /api/search to retrieve topK context snippets
 * 2) Asks the LLM to return STRICT JSON:
 *    { answer, citations: string[], followUps: string[] }
 * 3) Returns that JSON to the frontend
 *
 * It supports OpenRouter (preferred) or OpenAI â€” whichever key is present.
 * ENV required:
 *   - OPENROUTER_API_KEY (preferred)  OR  OPENAI_API_KEY
 *   - VERCEL_URL (set automatically in prod) for calling /api/search
 */

const need = (k) => {
  const v = process.env[k];
  if (!v || !v.trim()) throw new Error(`missing_env:${k}`);
  return v;
};
const opt = (k) => process.env[k] || '';

const toJSON = (res, status, obj) => {
  res.setHeader('Content-Type', 'application/json; charset=utf-8');
  res.status(status).send(JSON.stringify(obj));
};

async function postJSON(url, body, headers = {}) {
  const r = await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', ...headers },
    body: JSON.stringify(body),
  });
  if (!r.ok) {
    const text = await r.text().catch(() => '');
    throw new Error(`llm_http_${r.status}:${text.slice(0, 400)}`);
  }
  return r.json();
}

function getLLMConfig() {
  const orKey = opt('OPENROUTER_API_KEY');
  const oaKey = opt('OPENAI_API_KEY');
  if (orKey) {
    return {
      provider: 'openrouter',
      endpoint: 'https://openrouter.ai/api/v1/chat/completions',
      headers: { Authorization: `Bearer ${orKey}` },
      model: 'openai/gpt-4o-mini',
    };
  }
  if (oaKey) {
    return {
      provider: 'openai',
      endpoint: 'https://api.openai.com/v1/chat/completions',
      headers: { Authorization: `Bearer ${oaKey}` },
      model: 'gpt-4o-mini',
    };
  }
  throw new Error('no_llm_provider_configured');
}

const SYS_PROMPT = `
You are "Alan Ranger Assistant", a helpful photography guide and workshop assistant.
Write concise, friendly answers. Use bullets for tips/steps/gear. Provide concrete next steps.
Only use the provided context snippets. If you aren't sure, say so and suggest an action.

Return STRICT JSON ONLY:
{
  "answer": "markdown-friendly text (no HTML; **bold** and - bullets ok)",
  "citations": ["https://..."],
  "followUps": ["short suggestion", "another suggestion"]
}
`.trim();

function buildUserPrompt(query, matches) {
  const lines = matches.map((m, i) => {
    const cleaned = (m.content || '')
      .replace(/\s+/g, ' ')
      .slice(0, 1400);
    return `# Source ${i + 1}
URL: ${m.url}
Text: ${cleaned}`;
  });

  return `
User question: ${query}

Context snippets:
${lines.join('\n\n')}
`.trim();
}

async function embedAndSearch(query, topK) {
  // Prefer absolute URL in prod
  const base =
    process.env.VERCEL_URL
      ? `https://${process.env.VERCEL_URL}`
      : '';
  const r = await fetch(`${base}/api/search`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, topK }),
  });
  if (!r.ok) {
    const text = await r.text().catch(() => '');
    throw new Error(`search_failed_${r.status}:${text.slice(0, 300)}`);
  }
  const j = await r.json();
  if (!j || !Array.isArray(j.matches)) return { matches: [] };
  return j;
}

export default async function handler(req, res) {
  try {
    if (req.method !== 'POST') return toJSON(res, 405, { error: 'method_not_allowed' });

    const { query, topK = 8 } = req.body || {};
    if (!query || typeof query !== 'string') {
      return toJSON(res, 400, { error: 'bad_request', detail: 'Provide "query" string.' });
    }

    // 1) retrieve context
    const { matches } = await embedAndSearch(query, Math.max(1, Math.min(16, +topK || 8)));

    // 2) call LLM
    const { endpoint, headers, model } = getLLMConfig();
    const userPrompt = buildUserPrompt(query, matches);

    const body = {
      model,
      temperature: 0.2,
      messages: [
        { role: 'system', content: SYS_PROMPT },
        { role: 'user', content: userPrompt }
      ]
    };

    const j = await postJSON(endpoint, body, headers);

    let raw = (j?.choices?.[0]?.message?.content || '').trim();
    raw = raw.replace(/^```json\s*|\s*```$/g, ''); // strip code fences if present

    let out;
    try {
      out = JSON.parse(raw);
    } catch {
      out = {
        answer: raw || "I couldn't produce an answer. Please try rephrasing your question.",
        citations: Array.from(new Set(matches.map(m => m.url))).slice(0, 5),
        followUps: ["Show workshops near me", "Beginner camera settings", "Tuition and mentoring options"]
      };
    }

    // constrain citations to returned matches
    const known = new Set(matches.map(m => m.url));
    out.citations = (Array.isArray(out.citations) ? out.citations : [])
      .filter(u => known.has(u))
      .slice(0, 6);

    if (!Array.isArray(out.followUps) || out.followUps.length === 0) {
      out.followUps = ["Workshops near Coventry", "Landscape lens tips", "How to prepare for a workshop"];
    }

    return toJSON(res, 200, { ok: true, ...out });
  } catch (err) {
    return toJSON(res, 500, { error: 'server_error', detail: err?.message || String(err) });
  }
}
